{
    "link": "https://bbs.nga.cn/read.php?tid=39966115",
    "title": "LLaMa3 70b Instruct应该是个人LLM的答案了",
    "post_time": "2024-04-24 21:09",
    "uid": "63453772",
    "content": "首先评分和GPT4早期版本不相伯仲甚至更胜一筹，",
    "replies": [
        {
            "mid": "62073702",
            "mtime": "2024-04-24 21:22",
            "mcontent": "能取代客服吗，不可思议。你这个前端用了之后要不要加上一个联系人工的按钮呢。不加等于没有客服，加了等于if else 机器客服。先铺开再说吧，用的人不多，没法验证"
        },
        {
            "mid": "63453772",
            "mtime": "2024-04-24 22:38",
            "mcontent": "国内不晓得，我这边很多网站比如plotly和llamaindex已经用这个当文件小助手了。挺好用的"
        },
        {
            "mid": "60173489",
            "mtime": "2024-04-26 08:36",
            "mcontent": "70B是相对LLM较小，对个人看看现在a100月供都多少钱了"
        },
        {
            "mid": "63453772",
            "mtime": "2024-04-26 09:14",
            "mcontent": "所以说小公司或者有一定经济能力的～其实个人用8B就能顶2的70B了"
        },
        {
            "mid": "1781995",
            "mtime": "2024-04-26 10:31",
            "mcontent": "我是个api boy，用openapi的embeddings来向量化自己的知识库，然后利用向量数据库查询来辅助完成。请问下这种应用场景私有部署的话推荐哪个，最好能支持纯CPU跑的。"
        },
        {
            "mid": "63453772",
            "mtime": "2024-04-26 10:59",
            "mcontent": "cpu跑的我强烈不推荐……小型化的垃圾，能打那几个cpu跑不起来的……  但如果只是做embedding，你去huggingface拉个就好了的。其实你用openai api，ada啦么便宜，没必要本地化啊……"
        },
        {
            "mid": "64596823",
            "mtime": "2024-04-26 11:17",
            "mcontent": "推荐几个项目，基本都是基于llama.cpp来inference的，占用内存小还可以只用cpu。 ollama，gpt4all，都是在本地使用的。支持的模型包括llama3，不过我刚看参数量最大的是13B，对于个人来说也够了。 话说谷歌的gemma貌似也不错，应该是除了meta的大公司开源模型了。"
        },
        {
            "mid": "5254815",
            "mtime": "2024-04-26 14:09",
            "mcontent": "本地跑应该用 int4 的 command r 和 plus 在国内基于 llama3 全量微调出来之前，他才是本地离线最强的"
        },
        {
            "mid": "64149149",
            "mtime": "2024-04-27 04:21",
            "mcontent": "啊？command r和plus是什么？"
        },
        {
            "mid": "61540980",
            "mtime": "2024-04-28 07:39",
            "mcontent": "cohere 的，大概就是 gpt3.5 没削的水平"
        },
        {
            "mid": "5254815",
            "mtime": "2024-04-28 11:23",
            "mcontent": "Plus 是 4 代刚出的水平了"
        }
    ]
}