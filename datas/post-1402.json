{
    "link": "https://bbs.nga.cn/read.php?tid=39501812",
    "title": "[已解决]有没有精通elastic search的，请教个问题",
    "post_time": "2024-03-07 12:23",
    "uid": "60156798",
    "content": "大概2亿数据的集群，有一定实时性要求，集群默认刷新间隔1s。之前少部分操作使用refresh=true策略，耗时大概3s，后面切换了refresh=wait_for策略，耗时频繁暴涨到10s+。预期写请求是集群刷新间隔内返回，实际为什么会超时。",
    "replies": [
        {
            "mid": "42252406",
            "mtime": "2024-03-07 14:27",
            "mcontent": "工程问题插眼。"
        },
        {
            "mid": "60405384",
            "mtime": "2024-03-08 14:04",
            "mcontent": "插眼 zsbd"
        },
        {
            "mid": "63453772",
            "mtime": "2024-03-09 04:15",
            "mcontent": "猜是不是stackoverflow？"
        },
        {
            "mid": "16946151",
            "mtime": "2024-03-09 17:15",
            "mcontent": "集群规模多大，2亿数据1s刷新提这个需求的人就操蛋。硬件跟上了么"
        },
        {
            "mid": "60156798",
            "mtime": "2024-03-09 22:32",
            "mcontent": "回楼上，机器12个节点，都是32C64G，资源肯定够暂时的结论是因为update操作过于频繁，es对update支持不好底层原因暂时认定为7.x.x版本有软删除机制，需要手动关闭，所以频繁更新导致refresh时间太长，大概8s到10s，远高于刷新间隔可以结帖了"
        },
        {
            "mid": "60156798",
            "mtime": "2024-03-09 22:35",
            "mcontent": "后续改进的方向会尽可能从技术架构上去调整，将实时性依赖的字段全部从es去除，强依赖的字段走db，另外就是做好充分的降级预案"
        },
        {
            "mid": "62546497",
            "mtime": "2024-03-10 00:25",
            "mcontent": "不想大改架构的话，可以把局部update换成重新写入完整的新对象(最好走logstash)我之前3节点8c16g局部update的版本只能做到2000/s的写入，改成新的整个写入之后反而能干到8000/s了哦对了，如果真的更新很频繁的话，可以先全部存redis，搞个定时任务定期flush到es里。反正内存不值钱，使劲嗯造就完事了。我那个是因为后期只会更新一到两次所以没有上db的必要。"
        },
        {
            "mid": "60156798",
            "mtime": "2024-03-10 00:28",
            "mcontent": "完整写新对象可能出现ABA的问题，架构改造的方案之前已经定了，后续写入链路大部分都会走flink异步化，只有少量场景会直写 我的业务场景非常复杂，一个索引里有上百字段，来自不同数据源或者业务上游"
        },
        {
            "mid": "41975414",
            "mtime": "2024-03-10 03:46",
            "mcontent": "32c 64g只能说cpu够，磁盘最好要ssd。你的索引是多少副本，es的写入是要求主副都成功，你如果副本太多可能某一个长尾了，另外qps较高的单挑读写性能也是有影响。我认为和软删除关系不大 那玩意不理解不能关。update过程部份字段需要去fetch原本数据合并去生成新的，旧的标记删除，加上副本也要ack,然后wait for再等待完成后的下次refresh 这就慢了1、上ssd加速fetch2、加内存增大buff cache   或者direct memory部份3、实时性字段按你说的改架构4、知道_id也可直接设置false 取文档 规避es近实时特性"
        },
        {
            "mid": "60156798",
            "mtime": "2024-03-10 07:27",
            "mcontent": "现在是3副本，不过数据分布上有些不均衡，可能有影响SSD应该是，现在都是k8s挂载存储卷的，不需要考虑这个了软删除能关，es官方只是说不推荐。需要无感重建索引，强行指定参数为false，代价是不能用ccr了，异地多活机房没法同步数据，这个基本没啥影响目前来看主要是改架构，实时性字段依赖近实时中间件确实不太合理"
        }
    ]
}