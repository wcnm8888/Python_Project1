{
    "link": "https://bbs.nga.cn/read.php?tid=39220833",
    "title": "有搞深度学习的前辈吗？求助",
    "post_time": "2024-02-05 22:48",
    "uid": "64505991",
    "content": "背景:本人研一在读，软件工程专业。导师是一位新来的导师，没有任何资金和算力卡配置，目前跑模型是用自己带的台式电脑。",
    "replies": [
        {
            "mid": "65512062",
            "mtime": "2024-02-06 02:55",
            "mcontent": "没懂啊，你是怎么跑的。qa一般不都是拿大模型sft吗？上lora 一块4090 10k以内的数据最多跑两天，租一张4090 2块钱一小时啊，1000足够支撑到你毕业了，你找老板开发票报销就好了"
        },
        {
            "mid": "12787737",
            "mtime": "2024-02-06 10:49",
            "mcontent": "求问去哪里租2元一小时？"
        },
        {
            "mid": "64505991",
            "mtime": "2024-02-06 11:16",
            "mcontent": "我是3080跑的，他模型用的t5。。batchsize调到2勉强跑的快点，调大点就跑的巨慢，我看了一下应该是显存不够占了硬盘内存的缘故。至于报销这个问题。。我问过导师，导师说没资金不报销"
        },
        {
            "mid": "65512062",
            "mtime": "2024-02-06 11:56",
            "mcontent": "某autodl呗，学生价+会员价2.5吧好像，差一点点区别不大了"
        },
        {
            "mid": "65512062",
            "mtime": "2024-02-06 11:57",
            "mcontent": "你拿lora跑呗，全参数确是比较大速度应该慢一点，但也不至于几天吧，才多少数据量啊"
        },
        {
            "mid": "64505991",
            "mtime": "2024-02-06 12:13",
            "mcontent": "好的，谢谢，我去弄一弄"
        },
        {
            "mid": "65512062",
            "mtime": "2024-02-06 12:17",
            "mcontent": "3080显存确实太小了，租卡的话你把setting 我我帮你跑一下看看4090多久收敛，给你估个价你不需要告诉我具体的数据集，你只要说用的什么模型，source target len是多少，大概跑到多少个epoch收敛就行"
        },
        {
            "mid": "64505991",
            "mtime": "2024-02-06 14:19",
            "mcontent": "麻烦老哥。使用的t5模型，输入是512，输出不怎么记得。。电脑在学校，现在没法看。要跑到20个epoch才收敛我感觉他跑那么长时间的原因其中有一个就是他虽然是从hugging face上导入权重，但是没冻结t5的参数，在backward的时候更新了权重，导致参数量较大。"
        },
        {
            "mid": "65512062",
            "mtime": "2024-02-06 15:28",
            "mcontent": "我先睡了，有时差，明天起来帮你弄，t5有很多size，small large 3b etc，估计你用的large？数据集大小大概有多少也得说啊，train dataset的len"
        },
        {
            "mid": "64505991",
            "mtime": "2024-02-06 15:52",
            "mcontent": "好的。谢谢老哥了。实在不好意思，我属于新手，对于术语还是有些不太懂，所以说的不太全面模型用的是t5-basetrain dataset 有16000个样本对了。先前还忘记说了，他论文里是用了a6000跑了一天"
        },
        {
            "mid": "65512062",
            "mtime": "2024-02-06 16:04",
            "mcontent": "15k的话我没finetune过这个量级的，但是pretrain过，差不多你这个数据量级base就是20小时左右，一小时两块五，跑一次50块，说实话毕业论文除非sota特别高，加点trick怎么滴3-500总解决了，要么就上lora，速度翻倍性能掉点1-3不等，慢慢跑"
        },
        {
            "mid": "363254",
            "mtime": "2024-02-06 18:56",
            "mcontent": "就一张3080搞不了应用，搞搞理论吧"
        },
        {
            "mid": "64505991",
            "mtime": "2024-02-06 20:09",
            "mcontent": "好的，十分感谢老哥的指导。我感觉三五百的耗费，还可以做做"
        },
        {
            "mid": "64505991",
            "mtime": "2024-02-06 20:11",
            "mcontent": "好的，我再去研究研究。"
        }
    ]
}