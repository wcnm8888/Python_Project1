{
    "link": "https://bbs.nga.cn/read.php?tid=43228392",
    "title": "公司老板非让我我部署一个自己的AI，大佬们看我这样规划行不行",
    "post_time": "2025-02-08 16:39",
    "uid": "60328116",
    "content": "模型：deepseek R1",
    "replies": [
        {
            "mid": "42685479",
            "mtime": "2025-02-08 17:02",
            "mcontent": "训练R1？你认真的？我想想怎么说…一般来说，如果是企业自己部署一个增加生产力的模型，一块4090是起码的。如果公司还没相关基础设备，我建议是去AutoDL熟悉一下。模型选DeepSeek-R1-Distill-Qwen-32B。不需要reasoning就选Qwen2.5-7B-Instruct-1M。不需要ollama，而且我们最近测试ollama上的这个模型有点问题，和直接llama-factory启动生成的差别有点。但是训练…那个没几块A100下不来的。除非你和前段时间做countdown实验的那种。"
        },
        {
            "mid": "60328116",
            "mtime": "2025-02-08 17:06",
            "mcontent": "是那种简单的训练，外挂一个知识库，当顾客触发关键词，会回复我们指定的答案"
        },
        {
            "mid": "42685479",
            "mtime": "2025-02-08 17:11",
            "mcontent": "这种不需要训练，走RAG的逻辑。你github上搜一下dify，用他的工作流+知识库的方法。线上资源不够你训练的。如果要训练的话，你去github下一个llama-factory，用webui启动。不过SFT需要很多优质训练集，否则是反效果。我觉得贵司这个体量的训练集应该做不起来…"
        },
        {
            "mid": "60328116",
            "mtime": "2025-02-08 17:14",
            "mcontent": "感谢感谢"
        },
        {
            "mid": "64280834",
            "mtime": "2025-02-09 10:42",
            "mcontent": "别想着训练了，就算是lora精调也要你们有相当规模的数据(几百上千条是肯定的)和标注团队，以及懂管理标注的算法工程师，rag一下差不多得了"
        },
        {
            "mid": "60328116",
            "mtime": "2025-02-09 12:27",
            "mcontent": "好的"
        }
    ]
}