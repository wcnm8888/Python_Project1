{
    "link": "https://bbs.nga.cn/read.php?tid=40004963",
    "title": "本地部署llama，是选8块2080ti改22g还是4块",
    "post_time": "2024-04-28 14:12",
    "uid": "65730238",
    "content": "8块成本提升大概100%，能带来什么样的使用体验提升",
    "replies": [
        {
            "mid": "42191846",
            "mtime": "2024-04-28 18:24",
            "mcontent": "我也想组一个，但是又怕2080ti速度不怎么样"
        },
        {
            "mid": "60677230",
            "mtime": "2024-04-28 20:05",
            "mcontent": "1. 更长的input+output token数量，不会显存OOM2. 可以打更大的batch_size，变相提升可承受的qps基本就这俩，可以考虑下做混合精度的方案，接受一些模型性能下降换取模型显存占用的下降。"
        },
        {
            "mid": "65730238",
            "mtime": "2024-05-09 15:51",
            "mcontent": "现在用阿里的灵积模型试用，不训练，就算付费比自己搭建便宜多了"
        }
    ]
}