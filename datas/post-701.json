{
    "link": "https://bbs.nga.cn/read.php?tid=40957013",
    "title": "[讨论] 关于AI的一些思考讨论",
    "post_time": "2024-07-22 01:20",
    "uid": "65064480",
    "content": "交流交流AI",
    "replies": [
        {
            "mid": "63453772",
            "mtime": "2024-07-22 10:50",
            "mcontent": "现有LLM都是大型线性代数方程组，本质上不存在智能，只是个根据现有互联网数据集合的概率推断。 最近openai又在那造噱头的草莓项目就是之前那个Q*，所谓逻辑性的思维的AI，八字没一撇。Game of life也是随演化的复杂性变强。但在我的理解里是复杂过程根本上是简单过程的堆叠，现在大家也都是在找那个具有复杂潜力的基本单元，你看天天各种AI机构啊大牛啊都号称找到“更好的”transformer，但基本上都没有实用价值。"
        },
        {
            "mid": "544943",
            "mtime": "2024-07-22 11:19",
            "mcontent": "首先人脑运行的物理机制和意识的原理还没搞清，往人脑发展的这个目标本就不成立。然后目前这些基于深度学习技术的模型都只是拟合目标分布的非常复杂的数学公式的系数的集合，不存在类人智能。工程上可以有一系列方法让整个系统表现出一些似是而非的智能，但它与以往的人工智能系统没有本质上的区别，只是其在拟合能力上巨幅领先的结果。当然，这种系统在效用上比之前是遥遥领先的，只是它并非、也不会成为类人智能。"
        },
        {
            "mid": "41747939",
            "mtime": "2024-07-22 15:03",
            "mcontent": "2楼说的很准确了，稍微补充一点针对你问题的具体回答“真正类脑的AI模型不可能通过现有冯诺依曼架构的机器实现”这个其实没有定论，有些老路子比如遗传算法是往这个方向探究的，但是神经网络技术开始完善后工程效果被后者爆杀，现在已经几乎没什么人往这个方向研究了。所以也不是绝对不可能，只是进度太慢已经没人往这个方向的科技树投入“目前AI从业者只是希望其能协助人类完成工作而不是创造一个‘人类’？”。大部分“AI从业者”只是个打卡上班的调参技术员，实际上并没有参与到AI模型的研发，行业的总体走向不是技术员能左右的；对于真的能决定走向的AI研究者来说，更关心的是“在完成特定任务时准确率能提高多少个百分点”，并不在意使用的方法是类人智能模型还是基于统计拟合的数学模型，使用后者单纯是因为在陆续的研究和实验中发现到后者的准确率(哪怕在没有使用适配化硬件的前提下)比前者高太多。这种比较也不是短时间内拍脑袋作出的，神经网络的准确率开始显著优于标准线、有工业化价值的时间点大概是2012年的AlexNet论文发表，这之前 Alex Krizhevsky 和 Ilya Sutskever 的老师 Geoffrey Hinton 研究神经网络结构已经做了差不多30年"
        },
        {
            "mid": "60096900",
            "mtime": "2024-08-01 08:53",
            "mcontent": "我就是你眼中的曾经的ai从业者，也曾经做过很多模型工程。但由于自己学力有限，我已经转做自动化方向了。现在的ai技术是脱胎于机器学习，计算机视觉，和自然语言处理。这些技术和类脑理论唯一的链接是祖母细胞学说，祖母细胞学说并没有得到完全的证实，但是有很多佐证。其实你的议题最核心的东西是神经网络能否具有逻辑推理能力。目前这块在理论上，我接触到最新的前沿是意识机，逻辑推理最基本的底层是基于上下文的决策。而目前的ai模型只是基于统计学做的概率复现。虽然大模型出现了量变到质变的一些涌现现象，但还不具有良好的决策机制。甚至这个成为它最被诟病的地方。所以它只能做辅助决策，就是因为基于上下文决策这个东西太难做了。对于类脑智能而言，不是说冯诺依曼架构做不出来，而是目前任何计算机架构可能都做不出来。我认为，要做到这个，先得突破硬件算力，才能在更高的算力体系级上讨论上下文的模拟。毕竟做一次决策可能需要几百次推理加上下文评估。"
        },
        {
            "mid": "38359754",
            "mtime": "2024-08-08 08:47",
            "mcontent": "你们需要Amadeus。"
        },
        {
            "mid": "65496206",
            "mtime": "2024-08-12 09:08",
            "mcontent": "从神经网络到现在transform，本身深度学习就是模仿人的大脑来的。CNN尤为明显。完全是模拟人类认知去的。你所谓的类人和那些电视剧的类人真的差太远了。可以说如果那些类人是 100，以前的机械代码就是0，而CNN可以是0.几，现在的LLM是1。和100还有太大太大的差距。我觉得我们有生之年是看不到那种类人智能的出现。顺便说下我认为类人需要的以下四个模块：收集信息，理解信息，选择性存储信息，选择性遗忘信息。前两者其实现在已经基本上做到了，CNN 和LLM，后两者还是很关键的。目前一点没头绪。LLM和现在的人出现最大的区别就是我们活了太久了，而LLM能存储的历史信息太少了。如果LLM能存20年以上的信息，那它即使全能的。至于你说意识，那是不可能的。我们现在搞得安么多深度学习和意识没有半毛钱关系。不要被AI这个名字骗了，说到底，我们搞得就是深度学习。"
        },
        {
            "mid": "65406155",
            "mtime": "2024-08-12 11:26",
            "mcontent": "不好说 AI算法有个非常灵活的地方 随机数个人认为 随机数让冯诺依曼体系类脑成为可能"
        },
        {
            "mid": "65283028",
            "mtime": "2024-08-15 16:47",
            "mcontent": "其实我觉得这个问题的本质是，人脑的神经活动能否被数学公式所描述如果可以的话，AI理论上就能近似模拟所有的神经活动当然很可能全世界的算力凑一块发现还不够模拟的"
        },
        {
            "mid": "60013704",
            "mtime": "2024-08-15 17:23",
            "mcontent": "从上到下，从下到上，选择你的屁股"
        },
        {
            "mid": "41747939",
            "mtime": "2024-08-16 14:37",
            "mcontent": "AI的训练-推理构造就和人脑不一样，人脑每一台都是独立的训练-推理一体机，AI实际上是进行单次训练后把训练好的副本发送到所有终端进行同源推理终端的推理成本是非常低廉的，低廉到各家大模型厂商可以把轻量级模型的推理端免费发给大众随便玩来宣传。而训练端即使算力成本非常高，就算效率低到举大公司之力才能才能模仿人脑也无所谓，只要能在推理端回收成本就可行这也能看出来AI的结构最基层架构和人的差异大到成本计算逻辑都不一样"
        }
    ]
}