{
    "link": "https://bbs.nga.cn/read.php?tid=40963492",
    "title": "问个爬虫robots.txt相关的问题",
    "post_time": "2024-07-22 16:52",
    "uid": "2379932",
    "content": "楼主最近研究python的爬虫，了解了下robots.txt。",
    "replies": [
        {
            "mid": "62627428",
            "mtime": "2024-07-22 17:03",
            "mcontent": "君子协议，看你是君子还是小人"
        },
        {
            "mid": "65137266",
            "mtime": "2024-07-22 17:46",
            "mcontent": "robots.txt就相当于[游客止步]一类的指示牌，它并没有硬性的拦截功能。你非要进人家当然可以事后找你麻烦，例如封禁ip，法律起诉等等，但前提是找的到人，如果伪装了ip等信息，识别不出来你这个人，那找麻烦就无从谈起了。理想情况当然是每个人写的程序逻辑很自觉的遵守上面写的内容，说不能爬我就绝对不访问那些路径。但实践中纯粹是看程序员的职业道德了。"
        },
        {
            "mid": "992969",
            "mtime": "2024-07-23 09:17",
            "mcontent": "你说是不是要遵守那肯定要遵守你说不遵守会怎么样不会怎么样你说怎么样会进去包括但不限1 爬太多/快，把服务器爆了2 拿爬来的东西去干违法/侵权的事情然而这两点和robot.txt半毛钱关系也没有如果你就是自己学习爬几个页面玩玩，人家都懒得理你"
        },
        {
            "mid": "38113794",
            "mtime": "2024-07-25 14:57",
            "mcontent": "别开多进程，爬完一个页面sleep1-2秒这样对方的it懒得来找你"
        },
        {
            "mid": "60029705",
            "mtime": "2024-07-29 17:14",
            "mcontent": "这个文件只是表明服务器的态度，跟法律，规则不相关。"
        },
        {
            "mid": "63578770",
            "mtime": "2024-08-06 14:52",
            "mcontent": "一个申明文件，没有硬性要求，就算是谷歌这种大厂也会变通执行"
        }
    ]
}